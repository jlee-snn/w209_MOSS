<!doctype html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/css/bootstrap.min.css">
	<link rel="stylesheet" href="/static/main.css">
	<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js"></script>
	<script src="http://d3js.org/d3.v3.min.js"></script>
	<script src="/static/app.js" charset="utf-8"></script>
	<script>
	$(document).ready(function() {
    $("#btnFetch").click(function() {
      // disable button
      $(this).prop("disabled", false);
      // add spinner to button
      $(this).html(
        `<span class="spinner-border spinner-border-sm" role="status" aria-hidden="true"></span> Loading...`
      );
    });
	});
	</script>
</head>
<body>
	<title>Python Flask Multiple Files Upload Example</title>
	<div style="background-color:antiquewhite;">
		<h1><center>MOSS Dashboard</center></h1>
		<h2><center>Select file(s) to upload</center></h2>
		<p>
			{% with messages = get_flashed_messages() %}
			{% if messages %}
				<ul class=flashes>
				{% for message in messages %}
				<li>{{ message }}</li>
				{% endfor %}
				</ul>
			{% endif %}
			{% endwith %}
		</p>
		<form method="post" action="/" enctype="multipart/form-data">
			<dl>
				<p>
					<input type="file" name="files[]" multiple="true" autocomplete="off" required>
				</p>
			</dl>
			<p>
			<button type="submit" id="btnFetch" class="btn btn-primary mb-2">Submit</button>
			</p>
		</form>
	</div>

	<div style="background-color:beige">
		<h2><center>MOSS Dashboard Usage</center></h2>
		<h4 style="margin: 30px 30px;">Simplifying Model interpretability for Data Scientists</h4>
		<p style="margin: 30px 30px;">Model interpretability is a common challenge that many data scientists face, especially with black box models such as neural networks and decision trees. To help address this, the MOSS dashboard provides visualizations from the data results that are provided by LIME (Local Interpretable Model-agnostic Explanations), a novel explanation technique that explains the prediction of any classifier in an interpretable and faithful manner by learning a interpretable model locally around the prediction. </p>
		<p style="margin: 30px 30px;">To do this, our proof-of-concept dashboard tool ingests a binary classification model for text classification on whether the email is about Christianity or Atheism and relevant test data and leveraging the LIME python library, displays its results in a human-readable manner. Below are instructions to do this: </p>
		<ol style="margin: 30px 30px;">
			<li>Change the name of target variable to “target”</li>
			<li>Select and load in a model pickle file and csv test data</li>
			<li>Interpret dashboard results</li>
		</ol>
		<p style="margin: 30px 30px;">The dashboard is divided into 3 sections:</p>
		<ol style="margin: 30px 30px;">
			<li>LIME output horizontal bar chart in the top left that for one specific input text from the test data that shows the impact (weighting) of key words in text towards whether it is related to Christianity or Atheism </li>
			<li>The unstructured text from the test data with key words highlighted in the top right</li>
			<li>A table of all test data text records with index and their model output probabilities of being about Christianity or Atheism. By selecting a record in this table, the above two sections update to reflect that text</li>
		</ol>
	</div>
</body>
